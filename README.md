# PaLI-A-Jointly-Scaled-Multilingual-Language-Image-Model-Paper-Presentation

# Outline
- [Overview](#Overview)
- [Model Architecture](#Model Architecture)
- [Data](#Data)
- [Pretraining Tasks](#Pretraining Tasks)
- [Testing](#Testing)
- [Limitations/Biases](#Limitations/Biases)
- [Critical Analysis](#Critical Analysis)
- [Link](#Link)

# Overview

> Increasing neural network capacity has been a successful trend in the modeling of language and vision tasks. Language models such as G5 and GPT-3 have shown significant advantages from training large Transformers on large amounts text data. On the other hand, vision models such as CNNs and Vision Transformers have seen similar benefits from scaling but to a lesser extent compared to language models. Language-and-vision modeling are also popular now dealing with problems like Image Captioning and Visual Question-Answering. 

# Model Architecture

# Data

Data source: https://www.kaggle.com/datasets/ananthu017/emotion-detection-fer

> The data was uploaded to Google Drive from Kaggle, and it contains 35,685 emotion images in total and categorized them into 7 different categories (sad, neutral, happy, angry, disgusted, surprised, fearful). All the emotion images are saved in png format and each of them has a shape of 48x48 pixels in grayscale. However, we realized that the data labels were not all sufficiently represented: all the other emotion categories have over 4,000 image data, while for the disgusted category had about 500 images available. This can potentially cause problems later in the project. Therefore, we decided to remove the disgusted category from the data, which means only six emotions (sad, neutral, happy, angry, surprised, fearful) will be used for classification. This is done to avoid a data imbalance problem. 

# Pretraining Tasks


# Testing


# Limitations/Biases


# Critical Analysis


# Link
